{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_konlpy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMRxD5RickLQQw98VE6xj2Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yyyyyjkim/review_analysis/blob/master/2_konlpy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUpYUx1XNk-j",
        "colab_type": "code",
        "outputId": "fc14fc70-ced2-4591-801c-4162c0a0f36b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTvYTJIRNoeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KX_T4zqfNwh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-*- coding: utf-8 -*-"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-e8DFgpN0UK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pickle\n",
        "from konlpy.tag import Hannanum\n",
        "from konlpy.tag import Kkma\n",
        "from konlpy.tag import Mecab\n",
        "from konlpy.tag import Komoran\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZtCftNnN8LO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/comment_analysis/data/review.pickle', 'rb') as f:\n",
        "    review = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgF4_Qw5YEN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class nlp:\n",
        "  def __init__(self,text):\n",
        "    self.twitter = Okt()\n",
        "    self.tidy = [re.sub('[\\[\\]!\"#$%&\\'()*+,/:;<=>?@\\^_`{|}~-‚úîÔ∏èüôèüèªüëçü§óüíïüòò]|BEST\\n|Ïû¨Íµ¨Îß§\\n|ÌïúÎã¨ÏÇ¨Ïö©Í∏∞\\n','',sent) for sent in text]\n",
        "    self.tidy = [re.sub('\\n',' ',sent) for sent in self.tidy]\n",
        "\n",
        "  def get_morphs(self):\n",
        "    pos_text = [self.twitter.morphs(sent) for sent in self.tidy]\n",
        "    corpus = [\" \".join(word) for word in pos_text]\n",
        "    corpus = list(filter(lambda x: len(x)!=0, corpus))\n",
        "    return(corpus)\n",
        "\n",
        "  def get_pos(self):\n",
        "    pos_text = [self.twitter.pos(sent) for sent in self.tidy]\n",
        "    pos_text = [[word for word, tag in sent if tag == 'Noun' or tag=='Verb' or tag=='Adjective'] for sent in pos_text]\n",
        "    corpus = [\" \".join(word) for word in pos_text]\n",
        "    corpus = list(filter(lambda x: len(x)!=0, corpus))\n",
        "    return(corpus)\n",
        "\n",
        "  def get_noun(self):\n",
        "    pos_text = [self.twitter.nouns(sent) for sent in self.tidy]\n",
        "    corpus = [\" \".join(word) for word in pos_text]\n",
        "    corpus = list(filter(lambda x: len(x)!=0, corpus))\n",
        "    return(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVTPhKyLZk5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = nlp(review)\n",
        "nlp.tidy\n",
        "pos = nlp.get_pos()\n",
        "morphs = nlp.get_morphs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60RGYhW4PJG_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/comment_analysis/data/nlp.pickle','wb') as f:\n",
        "  pickle.dump(nlp,f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}