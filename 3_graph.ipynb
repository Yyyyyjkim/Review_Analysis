{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_graph.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMXC7os41PicQkPxS/1fNWV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yyyyyjkim/review_analysis/blob/master/3_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4aU8ZQQLHH0",
        "colab_type": "code",
        "outputId": "38059d22-819d-48f6-e56a-fb9d051f5c80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgFr4AzGLKh5",
        "colab_type": "code",
        "outputId": "1a324dfe-8c92-4c8b-f0dd-fc937035cb16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "!pip install sklearn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mplxjpkRLMq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn as sk\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import normalize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8S9onWtP_-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/comment_analysis/data/pos.pickle', 'rb') as f:\n",
        "    pos = pickle.load(f)\n",
        "with open('/content/drive/My Drive/comment_analysis/data/morphs.pickle', 'rb') as f:\n",
        "    morphs = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpjk1qWkLQcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# corpus : sentence(row) / words(columns)\n",
        "class graph:\n",
        "  def __init__(self):\n",
        "    self.tfidf = TfidfVectorizer()\n",
        "    self.counter = CountVectorizer()\n",
        "\n",
        "  def graph_sent(self,corpus):\n",
        "    mat_tfidf = self.tfidf.fit_transform(corpus).toarray()\n",
        "    graph_tfidf = np.dot(mat_tfidf,mat_tfidf.T)\n",
        "    return graph_tfidf\n",
        "\n",
        "  def graph_word(self,corpus):\n",
        "    mat_count = normalize(self.counter.fit_transform(corpus).toarray().astype(float),axis=0) #왜 normalize 하지?\n",
        "    vocab = self.counter.vocabulary_ # word:count\n",
        "    graph_word = np.dot(mat_count.T,mat_count)\n",
        "    words = {vocab[word]:word for word in vocab} # count:word\n",
        "    return graph_word, words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu3f49VjP7bE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "graph = graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juH6uvi7QKes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_graph = graph.graph_sent(morphs)\n",
        "word_graph, words = graph.graph_word(morphs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z31FqBZtQ4zn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/comment_analysis/data/graph.pickle','wb') as f:\n",
        "  pickle.dump(graph,f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}