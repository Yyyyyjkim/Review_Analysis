{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_crawling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMy0BUGz5FN0uRgQzqFXpqE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yyyyyjkim/review_analysis/blob/master/1_crawling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m__xhcvT2UW4",
        "colab_type": "code",
        "outputId": "ead631db-740f-4fa8-c88f-f2cf40168e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsMOHnHxpjEM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!pip install requests\n",
        "!pip install bs4\n",
        "!pip install selenium"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQAFCXLTpOQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XErav97dat9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class crawling:\n",
        "  def __init__(self):\n",
        "    self.options = webdriver.ChromeOptions()\n",
        "    self.options.add_argument('--headless')\n",
        "    self.options.add_argument('--no-sandbox')\n",
        "    self.options.add_argument('--disable-dev-shm-usage')\n",
        "    self.driver = webdriver.Chrome('chromedriver',options=self.options)\n",
        "  \n",
        "  def get_text(self,url,sorting,pagenum):\n",
        "    # go to review page and sorted by sorting\n",
        "    self.driver.get(url)\n",
        "    self.driver.find_element_by_xpath(\"//div[@class='detail_tab_floatable']//li[@class='item']/a[@class='link N=a:tab.review']\").click()\n",
        "    time.sleep(5)\n",
        "    div_class = 'header_review _review_list_header'\n",
        "    ul_class = 'sort_list _review_list_header_sort'\n",
        "    path = f\"//div[@class='{div_class}']//ul[@class='{ul_class}']//a[text()='{sorting}']\"\n",
        "    self.driver.find_element_by_xpath(path).click()\n",
        "    time.sleep(5)\n",
        "\n",
        "    # get text from 1 to pagenum\n",
        "    html = self.driver.page_source\n",
        "    soup = BeautifulSoup(html,'html.parser')\n",
        "    review_page = soup.find_all('p',class_='review_text _review_text')\n",
        "    review = [each_line.get_text().strip() for each_line in review_page[:20]]\n",
        "    for page in range(2,(pagenum+1)):\n",
        "        path_page = f\"//nav[@class='module_pagination _review_list_page']//a[text()='{page}']\"\n",
        "        self.driver.find_element_by_xpath(path_page).click()\n",
        "        time.sleep(5)\n",
        "        html = self.driver.page_source\n",
        "        soup = BeautifulSoup(html, 'html.parser')\n",
        "        review_page = soup.find_all('p',class_='review_text _review_text')\n",
        "        review_page = [each_line.get_text().strip() for each_line in review_page[:20]]\n",
        "        review.extend(review_page)\n",
        "    \n",
        "    return review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-PvXyTXfc2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crawl = crawling()\n",
        "text_rank =crawl.get_text(\"https://smartstore.naver.com/jainystore/products/2455969597\",\"랭킹순\",10)\n",
        "# text_date =crawl.get_text(\"https://smartstore.naver.com/jainystore/products/2455969597\",\"최신순\",10)\n",
        "# text_desc =crawl.get_text(\"https://smartstore.naver.com/jainystore/products/2455969597\",\"평점 높은순\",10)\n",
        "# text_asc =crawl.get_text(\"https://smartstore.naver.com/jainystore/products/2455969597\",\"평점 낮은순\",10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olrlIMoXdD5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mA0n2dHm-hr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/comment_analysis/data/crawling.pickle','wb') as f:\n",
        "  pickle.dump(crawling,f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}